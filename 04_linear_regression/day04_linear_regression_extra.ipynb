{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MADMO Course\n",
    "\n",
    "### Seminar 4: extra materials\n",
    "### Linear Regression for Tabular Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use a dataset example \"California Housing\" from [scikit-learn.datasets](https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset). \n",
    "\n",
    "```\n",
    "This dataset was derived from the 1990 U.S. census, using one row per census block group. A block group is the smallest geographical unit for which the U.S. Census Bureau publishes sample data (a block group typically has a population of 600 to 3,000 people).\n",
    "\n",
    "The target variable is the median house value for California districts, expressed in hundreds of thousands of dollars ($100,000).\n",
    "```\n",
    "\n",
    "For further work, let's do the following:\n",
    "* Conduct reasonable data preprocessing.\n",
    "* Divide the data into training, validation and test samples\n",
    "* Perform hyperparameter search and select the best approach among the following:\n",
    "- LinearRegression\n",
    "- Lasso (L1-regularized linear regression)\n",
    "- Ridge (L2-regularized linear regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.datasets import fetch_california_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dict = fetch_california_housing()\n",
    "feature_names = dataset_dict[\"feature_names\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.DataFrame(dataset_dict[\"data\"], columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df[\"target\"] = dataset_dict[\"target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check information about each feature, See, if there is missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total # objects: {len(data_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Statistics for each feature\")\n",
    "data_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, no missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build some graphics, and see correlation between features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot target distribution\n",
    "data_df.hist(\"target\", bins=30);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot distributions for other features to estimate their range\n",
    "def visualize_df_columns(used_df, used_col_names):\n",
    "    fig, ax = plt.subplots(len(used_col_names) // 2, 2, figsize=(20, 20))\n",
    "    for i, name_feat in enumerate(used_col_names):\n",
    "        used_df[name_feat].hist(bins=30, ax=ax[i // 2, i % 2])\n",
    "        ax[i // 2, i % 2].set_title(name_feat)\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_df_columns(data_df, feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot correlation finally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.corr() --> correlation matrix\n",
    "sns.heatmap(data_df.corr(), annot=True, cmap=\"RdYlGn\", linewidths=0.2)\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(10, 8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, that was really brief eda, we aren't going to focus on it today\n",
    "\n",
    "Next steps are:\n",
    "\n",
    "1. Split dataset into train / val / test\n",
    "2. Fit some models\n",
    "3. Evaluate them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    data_df.drop(\"target\", 1).values, data_df[\"target\"].values, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are going to try out 3 models:\n",
    "\n",
    "`sklearn.linear_model.LinearRegression` - this model tries to find analytical solution for:\n",
    "$$\n",
    "\\widehat{w} = argmin_w \\sum{(y - Xw)^2}\n",
    "$$\n",
    "$$\n",
    "\\widehat{w} = (X^TX)^{-1}X^Ty\n",
    "$$\n",
    "`sklearn.linear_model.Ridge` - this is also linear model, but with l2 regularization. It also has analytical solution\n",
    "\n",
    "`sklearn.linear_model.Lasso` - this is linear model with l1 regularization. Unfortunately it has not any analytical solution, so model tries to find it iteratively (SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso, LinearRegression, Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train, Y_train)\n",
    "\n",
    "alpha = 0.5\n",
    "ridge = Ridge(alpha=alpha)\n",
    "ridge.fit(X_train, Y_train)\n",
    "\n",
    "lasso = Lasso(alpha=alpha)\n",
    "lasso.fit(X_train, Y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see some metrics for evaluation:\n",
    "\n",
    "[Mean Squared Error](https://en.wikipedia.org/wiki/Mean_squared_error)\n",
    "\n",
    "[Mean Absolute Error](https://en.wikipedia.org/wiki/Mean_absolute_error)\n",
    "\n",
    "[R2 score](https://en.wikipedia.org/wiki/Coefficient_of_determination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_predict = lr.predict(X_test)\n",
    "mae_lr = mean_absolute_error(Y_test, lr_predict)\n",
    "mse_lr = mean_squared_error(Y_test, lr_predict)\n",
    "r2_lr = r2_score(Y_test, lr_predict)\n",
    "\n",
    "ridge_predict = ridge.predict(X_test)\n",
    "mae_ridge = mean_absolute_error(Y_test, ridge_predict)\n",
    "mse_ridge = mean_squared_error(Y_test, ridge_predict)\n",
    "r2_ridge = r2_score(Y_test, ridge_predict)\n",
    "\n",
    "lasso_predict = lasso.predict(X_test)\n",
    "mae_lasso = mean_absolute_error(Y_test, lasso_predict)\n",
    "mse_lasso = mean_squared_error(Y_test, lasso_predict)\n",
    "r2_lasso = r2_score(Y_test, lasso_predict)\n",
    "\n",
    "print(\"Linear regression:\")\n",
    "print(f\"MSE: {mse_lr}\")\n",
    "print(f\"MAE: {mae_lr}\")\n",
    "print(f\"R2: {r2_lr}\")\n",
    "print(\"-\" * 10)\n",
    "print(\"Ridge regression:\")\n",
    "print(f\"MSE: {mse_ridge}\")\n",
    "print(f\"MAE: {mae_ridge}\")\n",
    "print(f\"R2: {r2_ridge}\")\n",
    "print(\"-\" * 10)\n",
    "print(\"Lasso regression:\")\n",
    "print(f\"MSE: {mse_lasso}\")\n",
    "print(f\"MAE: {mae_lasso}\")\n",
    "print(f\"R2: {r2_lasso}\")\n",
    "print(\"-\" * 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra tip: preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes, it is very usefull to preprocess your data -> center it, or put it in some range\n",
    "\n",
    "`sklearn` has special module for it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In out case it is no use: our data is quite okay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = X_train.copy()\n",
    "X_test_scaled = X_test.copy()\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_scaled, Y_train)\n",
    "\n",
    "print(\"Unscaled\")\n",
    "print(\"Train MSE:\", mean_squared_error(Y_train, model.predict(X_train_scaled)))\n",
    "print(\"Test MSE:\", mean_squared_error(Y_test, model.predict(X_test_scaled)))\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(X_train_scaled)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(scaler.transform(X_train_scaled), Y_train)\n",
    "print(\"Scaled (Standard scaler)\")\n",
    "print(\"Train MSE:\", mean_squared_error(Y_train, model.predict(scaler.transform(X_train_scaled))))\n",
    "print(\"Test MSE:\", mean_squared_error(Y_test, model.predict(scaler.transform(X_test_scaled))))\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "scaler.fit(X_train_scaled)\n",
    "\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(scaler.transform(X_train_scaled), Y_train)\n",
    "print(\"Scaled (MinMax scaler)\")\n",
    "print(\"Train MSE:\", mean_squared_error(Y_train, model.predict(scaler.transform(X_train_scaled))))\n",
    "print(\"Test MSE:\", mean_squared_error(Y_test, model.predict(scaler.transform(X_test_scaled))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But if we stretch some features and add some noise, scaling will become very handy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = X_train.copy()\n",
    "X_test_scaled = X_test.copy()\n",
    "\n",
    "# streching + noising\n",
    "for _ in range(9):\n",
    "    X_train_scaled[:, 3] *= 150\n",
    "    X_train_scaled[:, 2] *= 200\n",
    "    X_test_scaled[:, 3] *= 150\n",
    "    X_test_scaled[:, 2] *= 200\n",
    "\n",
    "    X_train_scaled[:, 3] += np.random.normal(size=X_train_scaled.shape[0])\n",
    "    X_train_scaled[:, 2] += np.random.normal(size=X_train_scaled.shape[0])\n",
    "    X_test_scaled[:, 3] += np.random.normal(size=X_test_scaled.shape[0])\n",
    "    X_test_scaled[:, 2] += np.random.normal(size=X_test_scaled.shape[0])\n",
    "\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_scaled, Y_train)\n",
    "\n",
    "print(\"Unscaled\")\n",
    "print(\"Train MSE:\", mean_squared_error(Y_train, model.predict(X_train_scaled)))\n",
    "print(\"Test MSE:\", mean_squared_error(Y_test, model.predict(X_test_scaled)))\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(X_train_scaled)\n",
    "\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(scaler.transform(X_train_scaled), Y_train)\n",
    "print(\"Scaled (Standard scaler)\")\n",
    "print(\"Train MSE:\", mean_squared_error(Y_train, model.predict(scaler.transform(X_train_scaled))))\n",
    "print(\"Test MSE:\", mean_squared_error(Y_test, model.predict(scaler.transform(X_test_scaled))))\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "scaler.fit(X_train_scaled)\n",
    "\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(scaler.transform(X_train_scaled), Y_train)\n",
    "print(\"Scaled (MinMax scaler)\")\n",
    "print(\"Train MSE:\", mean_squared_error(Y_train, model.predict(scaler.transform(X_train_scaled))))\n",
    "print(\"Test MSE:\", mean_squared_error(Y_test, model.predict(scaler.transform(X_test_scaled))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** scaler must be fitted only on `train` part. Never use `scaler.fit(test)`! It is supposed to be `scaler.transform(test)` only, if you don't want to get any data leaking in your modeling pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra tip: hyperparameters search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sklearn.model_selection` has special class called `GridSearchCV` to find best hyperparameters for your model:\n",
    "1. It iterates over all possible combinations of hyperparameters, you had given it\n",
    "2. It produce cross-validation\n",
    "3. Based on cross-validation metrics it choses the best parameters\n",
    "\n",
    "Let's see, how it is done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_plot(model, parameter_dict):\n",
    "    \"\"\"This function takes a model and parameters\n",
    "    dict as input and plot a graph of MSE loss VS parameter value\"\"\"\n",
    "    gscv = GridSearchCV(model, parameter_dict, cv=3, verbose=1)\n",
    "    gscv.fit(X_train, Y_train)\n",
    "    plt.errorbar(\n",
    "        gscv.param_grid[\"alpha\"],\n",
    "        gscv.cv_results_[\"mean_test_score\"],\n",
    "        gscv.cv_results_[\"std_test_score\"],\n",
    "        capsize=5,\n",
    "        label=model.__str__().split(\"(\")[0],\n",
    "    )\n",
    "    plt.xscale(\"log\")\n",
    "    plt.xlabel(\"alpha\")\n",
    "    plt.ylabel(\"negative MSE\")\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    return gscv.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to find best regularization parameter for `Ridge`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Ridge()\n",
    "params = {\"alpha\": np.linspace(0.0001, 20.0)}\n",
    "\n",
    "best_ridge = train_and_plot(model, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Extra:* see `sklearn.model_selection.RandomizedSearchCV` and try it out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Extra2:* find best params for `sklearn.linear_model.SGDRegressor`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Extra3:* Make `GridSearchCV` pipeline with scaled features (hint: you can't transform your data before passing it to `gscv.fit` because it will result in data leakage - you should be using [pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra tip: predicting log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes, the log distribution of your target is easier to predict. Let's see:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot target distribution\n",
    "plt.title(\"target\")\n",
    "data_df[\"target\"].hist(bins=30);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot log target distribution\n",
    "plt.title(\"target (log)\")\n",
    "data_df[\"target\"].apply(np.log).hist(bins=30);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train, Y_train)\n",
    "\n",
    "lr_predict = lr.predict(X_test)\n",
    "mae_lr = mean_absolute_error(Y_test, lr_predict)\n",
    "mse_lr = mean_squared_error(Y_test, lr_predict)\n",
    "r2_lr = r2_score(Y_test, lr_predict)\n",
    "\n",
    "print(\"Linear regression (raw target):\")\n",
    "print(f\"MSE: {mse_lr}\")\n",
    "print(f\"MAE: {mae_lr}\")\n",
    "print(f\"R2: {r2_lr}\")\n",
    "print(\"-\" * 10)\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, np.log(Y_train))\n",
    "\n",
    "lr_predict = lr.predict(X_test)\n",
    "mae_lr = mean_absolute_error(np.log(Y_test), lr_predict)\n",
    "mse_lr = mean_squared_error(np.log(Y_test), lr_predict)\n",
    "r2_lr = r2_score(np.log(Y_test), lr_predict)\n",
    "\n",
    "print(\"Linear regression (log target):\")\n",
    "print(f\"MSE: {mse_lr}\")\n",
    "print(f\"MAE: {mae_lr}\")\n",
    "print(f\"R2: {r2_lr}\")\n",
    "print(\"-\" * 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
